{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The principal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    \n",
    "    FILENAME = \"CTR.txt\"\n",
    "    \n",
    "    def __init__(self, path=FILENAME):\n",
    "        \"\"\"\n",
    "        Convert the text file into 2 matrix : one for the context and one for the true gain for each example.\n",
    "        \n",
    "        :param path: The path of the data file\n",
    "        \n",
    "        :type path: String\n",
    "        \"\"\"\n",
    "        with open(path, \"r\") as file:\n",
    "            lines = file.read().split(\"\\n\")\n",
    "            \n",
    "        #Extract data\n",
    "        lines = lines[:-1]\n",
    "        contexts = []\n",
    "        trueGains = []\n",
    "        for line in lines:\n",
    "            useless, context, trueGain = line.split(\":\")\n",
    "            contexts.append(context.split(\";\"))\n",
    "            trueGains.append(trueGain.split(\";\"))\n",
    "        self.numData = 1000\n",
    "        contexts = contexts[:self.numData]#To test with less data\n",
    "        trueGains = trueGains[:self.numData]#To test with less data\n",
    "        self.contexts = np.array(contexts, dtype=np.float32)\n",
    "        self.trueGains = np.array(trueGains, dtype=np.float32)\n",
    "        self.nb_arms = self.trueGains.shape[1]\n",
    "        \n",
    "        #Prepare usefull variable for statistics\n",
    "        self.averageGains = self.trueGains.sum(axis=0)#compute sum for each columns wich is the global gain for each arm\n",
    "        \n",
    "            \n",
    "    \n",
    "    def start(self, funcChoice):\n",
    "        \"\"\"\n",
    "        To start playing using the function given.\n",
    "        \n",
    "        :param funcChoice: The function to use for the choice\n",
    "        \n",
    "        :type funcChoice: Bandit.func()\n",
    "        \n",
    "        :return: A 2-uplet wich the optimal regret and the pseudo-optimal regret\n",
    "        :rtype: (float, float)\n",
    "        \"\"\"\n",
    "        self.gains = np.zeros(self.trueGains.shape[1], dtype=np.float32) #initialise the gains for each arms to 0\n",
    "        self.nbs = np.zeros(self.trueGains.shape[1], dtype=np.float32) #initialise the number of play for each arms to 0\n",
    "        self.statsOpti = {\"optimal\":0.0, 'staticBest':0.0}#to compute gain of optimal strategy and pseudo optimal strategy\n",
    "        self.time = 0#intialise time to 0\n",
    "        self.choices = []#to remember choices\n",
    "        \n",
    "        \n",
    "        #param for linUCB algorithm\n",
    "        \n",
    "        self.contextDim = self.contexts.shape[1] # context dimension (= 5)\n",
    "        self.alpha = 0.1 \n",
    "        self.A = np.zeros((self.trueGains.shape[1], self.contextDim, self.contextDim)) # Aa = Da.T*Da + Id\n",
    "        self.A[:] = np.identity(self.contextDim) # we initialise A for each arm to an identity matrix (dxd) \n",
    "        self.B = np.zeros((self.trueGains.shape[1], self.contextDim)) # ba = Da.T*ca\n",
    "        self.Teta = np.zeros((self.trueGains.shape[1], self.contextDim)) # matrix of arms features\n",
    "        \n",
    "        for trueGain in self.trueGains:\n",
    "            \n",
    "            choice = funcChoice()#get the choice with the choosen method\n",
    "            self.choices.append(choice)\n",
    "            #update of current gains, number of play, optimal gain and pseudo optimal gain\n",
    "            self.gains[choice] += self.trueGains[self.time][choice]\n",
    "            self.nbs[choice] += 1\n",
    "            self.statsOpti[\"optimal\"] += self.trueGains[self.time][self.optimal()]\n",
    "            self.statsOpti[\"staticBest\"] += self.trueGains[self.time][self.staticBest()]\n",
    "            self.time += 1\n",
    "            \n",
    "        return self.statsOpti[\"optimal\"]-self.gains.sum(), self.statsOpti[\"staticBest\"]-self.gains.sum()\n",
    "            \n",
    "        \n",
    "            \n",
    "    def random(self):\n",
    "        \"\"\"\n",
    "        Implementation of random choice\n",
    "        \"\"\"\n",
    "        return np.random.randint(self.trueGains.shape[1])\n",
    "    \n",
    "    \n",
    "    def staticBest(self):\n",
    "        \"\"\"\n",
    "        Implementation of pseudo optimal (also named staticBest)\n",
    "        \"\"\"\n",
    "        return np.argmax(self.averageGains)\n",
    "    \n",
    "    \n",
    "    def optimal(self):\n",
    "        \"\"\"\n",
    "        Implementation of optimal\n",
    "        \"\"\"\n",
    "        return np.argmax(self.trueGains[self.time])\n",
    "    \n",
    "    \n",
    "    def ucb(self):\n",
    "        \"\"\"\n",
    "        Implementation od UCB\n",
    "        \"\"\"\n",
    "        if(self.time<self.nb_arms): #Initialisation to have first estimation\n",
    "            return self.time\n",
    "        else:\n",
    "            return np.argmax((self.gains/self.nbs)+np.sqrt(2*np.log(self.time+1)/self.nbs))\n",
    "        \n",
    "        \n",
    "    def linUCB(self):\n",
    "        \"\"\"\n",
    "        Implementation of linUCB algorithm\n",
    "        \"\"\"\n",
    "        if(self.time<self.nb_arms): #Initialisation to have first estimation\n",
    "            return self.time\n",
    "        \n",
    "        else:\n",
    "            proba = np.zeros(self.nb_arms)\n",
    "            context = self.contexts[self.time]\n",
    "            \n",
    "            for arm in range(self.nb_arms):\n",
    "                \n",
    "                invA = np.linalg.inv(self.A[arm])\n",
    "                self.Teta[arm] = np.dot(invA, self.B[arm]) # analytic reslut of ridge regression\n",
    "                proba[arm] = np.dot(self.Teta[arm], context) + self.alpha*np.sqrt(np.dot(np.dot(context.T,invA),context))\n",
    "            \n",
    "            choice = np.argmax(proba)\n",
    "            payoff = self.trueGains[self.time][choice]\n",
    "            \n",
    "            # Update choosen arm features\n",
    "            \n",
    "            self.A[choice] += np.dot(context,context.T)\n",
    "            self.B[choice] += payoff*context\n",
    "            \n",
    "            return choice\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation and variable printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.contexts.shape#(number of example; number of arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10341906 0.19069779 0.         0.10240139 0.03631242 0.07456195\n",
      "  0.23470241 0.         0.         0.07857373]\n",
      " [0.         0.         0.         0.0208271  0.         0.\n",
      "  0.02258593 0.         0.14654765 0.32459557]\n",
      " [0.10957462 0.13662645 0.         0.09841065 0.0747713  0.\n",
      "  0.         0.         0.01475992 0.19367686]]\n"
     ]
    }
   ],
   "source": [
    "print(b.trueGains[:3])#sample to see head data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply each function choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224.5064943432808, 185.38564492203295)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.start(b.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39.121072590351105, 0.00022316910326480865)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.start(b.staticBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.357929229736328e-06, -39.12084006331861)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.start(b.optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165.64649373292923, 126.52564431168139)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.start(b.ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76.71257954835892, 37.59173012711108)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.start(b.linUCB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as expected:\n",
    "- ucb is better than random \n",
    "- ucb is worse than pseudo-optimal wich is expected (and lin-UCB should be better)\n",
    "- optimal as an optimal regret of 0 because it is the optimal\n",
    "- staticBest as an pseudo-optimal of 0 because it is pseudo-optimal\n",
    "- optimal is better than pseudo-optimal\n",
    "- optimal regret is always greater than pseudo-optimal regret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
